{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "In this notebook I:  \n",
    "- Trained a linear regression model to predict the optimal rental price per day based on multiple features\n",
    "- Regularized the model for any overfitting  \n",
    "- Fine tuned the best hyperparameters to use  \n",
    "- Evaluated model robustness via a cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import  StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../data/get_around_pricing_project_cleaned.csv\"\n",
    "MODELS_FOLDER = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4842, 14)\n",
      "Index(['model_key', 'mileage', 'engine_power', 'fuel', 'paint_color',\n",
      "       'car_type', 'private_parking_available', 'has_gps',\n",
      "       'has_air_conditioning', 'automatic_car', 'has_getaround_connect',\n",
      "       'has_speed_regulator', 'winter_tires', 'rental_price_per_day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file of cleaned data\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target lenght: (4842,)\n",
      "Explanatory variables df shape: (4842, 13)\n"
     ]
    }
   ],
   "source": [
    "# Separate target from explanatory variables\n",
    "y = df[\"rental_price_per_day\"]\n",
    "X = df.drop([\"rental_price_per_day\"], axis=1)\n",
    "\n",
    "print('Target lenght:', y.shape)\n",
    "print('Explanatory variables df shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (3873, 13)\n",
      "y train shape (3873,)\n",
      "X test shape: (969, 13)\n",
      "y test shape (969,)\n"
     ]
    }
   ],
   "source": [
    "#Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('X train shape:', X_train.shape)\n",
    "print('y train shape', y_train.shape)\n",
    "print('X test shape:', X_test.shape)\n",
    "print('y test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Citroën' 234365 135 'diesel' 'black' 'estate' True True False False\n",
      "  True False True]\n",
      " ['Volkswagen' 57344 70 'diesel' 'grey' 'hatchback' False True False\n",
      "  False False False True]]\n",
      "[['Toyota' 193657 85 'diesel' 'silver' 'van' False False False False\n",
      "  False False True]\n",
      " ['Audi' 178112 170 'petrol' 'silver' 'sedan' True True True False False\n",
      "  False True]]\n",
      "\n",
      "[127, 109]\n",
      "[94, 37]\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframes to numpy arrays for pre-processing\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "print(X_train[0:2,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(y_train[0:2])\n",
    "print(y_test[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['mileage', 'engine_power']  at positions  [1, 2]\n",
      "Found categorical features  ['model_key', 'fuel', 'paint_color', 'car_type', 'private_parking_available', 'has_gps', 'has_air_conditioning', 'automatic_car', 'has_getaround_connect', 'has_speed_regulator', 'winter_tires']  at positions  [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "## Script re-used from scripts given during Jedha Bootcamp course \n",
    "\n",
    "# Automatically detect positions of numeric/categorical features in explanatory variables dataframe\n",
    "idx = 0\n",
    "numeric_features = []\n",
    "numeric_indices = []\n",
    "categorical_features = []\n",
    "categorical_indices = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "        numeric_indices.append(idx)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "        categorical_indices.append(idx)\n",
    "\n",
    "    idx = idx + 1\n",
    "\n",
    "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
    "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for pre-processing categorical features and standardizing numerical features\n",
    "\n",
    "# Normalization\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# One hot encoding\n",
    "categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "featureencoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_indices),    \n",
    "        ('num', numeric_transformer, numeric_indices)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define full pipeline including pre-processing and basline linear regressor\n",
    "baseline_regressor = Pipeline([\n",
    "        ('preprocessing', featureencoder),\n",
    "        ('lin_reg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "regressor_ridge = Pipeline([\n",
    "        ('preprocessing', featureencoder),\n",
    "        ('lin_reg', Ridge(alpha=1.5))\n",
    "    ])\n",
    "\n",
    "regressor_lasso = Pipeline([\n",
    "        ('preprocessing', featureencoder),\n",
    "        ('lin_reg', Lasso(alpha=1.5))\n",
    "    ])\n",
    "\n",
    "regressor_rf = Pipeline([\n",
    "        ('preprocessing', featureencoder),\n",
    "        ('lin_reg', RandomForestRegressor())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance  \n",
    "Evaluate performance of a baseline regressor model and compare to other regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline regressor\n",
      "R2 score on training set:  0.7164492031260445\n",
      "R2 score on test set:  0.6516031988969857\n",
      "##################\n",
      "Rigdge regressor\n",
      "R2 score on training set:  0.7140680243100068\n",
      "R2 score on test set:  0.6866344732555352\n",
      "##################\n",
      "Lasso regressor\n",
      "R2 score on training set:  0.6123740505563878\n",
      "R2 score on test set:  0.607668530839915\n",
      "##################\n",
      "Random Forest regressor\n",
      "R2 score on training set:  0.9659780533559799\n",
      "R2 score on test set:  0.7592812287945734\n"
     ]
    }
   ],
   "source": [
    "# Fit models and evaluate performance with coefficient of determination R^2\n",
    "\n",
    "print('Baseline regressor')\n",
    "baseline_regressor.fit(X_train, y_train)\n",
    "print(\"R2 score on training set: \", baseline_regressor.score(X_train,y_train))\n",
    "print(\"R2 score on test set: \", baseline_regressor.score(X_test,y_test))\n",
    "print('##################')\n",
    "print('Rigdge regressor')\n",
    "regressor_ridge.fit(X_train, y_train)\n",
    "print(\"R2 score on training set: \", regressor_ridge.score(X_train,y_train))\n",
    "print(\"R2 score on test set: \", regressor_ridge.score(X_test,y_test))\n",
    "print('##################')\n",
    "print('Lasso regressor')\n",
    "regressor_lasso.fit(X_train, y_train)\n",
    "print(\"R2 score on training set: \", regressor_lasso.score(X_train,y_train))\n",
    "print(\"R2 score on test set: \", regressor_lasso.score(X_test,y_test))\n",
    "print('##################')\n",
    "print('Random Forest regressor')\n",
    "regressor_rf.fit(X_train, y_train)\n",
    "print(\"R2 score on training set: \", regressor_rf.score(X_train,y_train))\n",
    "print(\"R2 score on test set: \", regressor_rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model hyperparameter tuning  \n",
    "Evaluate best hyperparameters to use for the model having the best performance  \n",
    "\n",
    "First use RandomizedSearch to narrow down the hyperparameters to use\n",
    "Secondly use GridSearch to fine tune on search for hyperparameters\n",
    "\n",
    "Randomized search code based on Hyperparameter tuning publication by Will Koehrsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized search: create random grid\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# First create the base model to tune\n",
    "regressor_rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "randomsearch = RandomizedSearchCV(estimator = regressor_rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = -1)\n",
    "\n",
    "X_train_t = featureencoder.fit_transform(X_train)\n",
    "X_test_t = featureencoder.transform(X_test)\n",
    "\n",
    "# Fit the random search model\n",
    "randomsearch.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Random Forest regressor:  {'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters found through randomized search\n",
    "print(\"Best hyperparameters for Random Forest regressor: \", randomsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Random Forest regressor:  {'max_depth': 70, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Best R2 score Random Forest :  0.7548610467394663\n"
     ]
    }
   ],
   "source": [
    "# Fine tune hyperparameter search\n",
    "\n",
    "# Perform Grid Search for best parameters for regressors\n",
    "regressor_rf = RandomForestRegressor()\n",
    "\n",
    "# Grid of values to be tested: \n",
    "params = {\n",
    "    'max_depth': [70,80, 90, 100],\n",
    "    'min_samples_split': [3, 4, 5],\n",
    "    'n_estimators': [1000,1200,1400]\n",
    "}\n",
    "gridsearch_rf = GridSearchCV(regressor_rf, param_grid = params, cv=5 ,verbose=0, n_jobs = -1)\n",
    "gridsearch_rf.fit(X_train_t, y_train)\n",
    "\n",
    "print(\"Best hyperparameters for Random Forest regressor: \", gridsearch_rf.best_params_)\n",
    "print(\"Best R2 score Random Forest : \", gridsearch_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final pipeline of best model using identified hyperparameters\n",
    "best_regressor_rf = Pipeline([\n",
    "        ('preprocessing', featureencoder),\n",
    "        ('lin_reg', RandomForestRegressor(n_estimators=1200, \n",
    "        min_samples_split=5, min_samples_leaf=1, max_features='sqrt', max_depth=80, bootstrap=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set:  0.9551267458505919\n",
      "R2 score on test set:  0.7431710778917816\n"
     ]
    }
   ],
   "source": [
    "best_regressor_rf.fit(X_train, y_train)\n",
    "print(\"R2 score on training set: \", best_regressor_rf.score(X_train,y_train))\n",
    "print(\"R2 score on test set: \", best_regressor_rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.789462</td>\n",
       "      <td>0.122772</td>\n",
       "      <td>0.567467</td>\n",
       "      <td>0.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.783456</td>\n",
       "      <td>0.097236</td>\n",
       "      <td>0.618854</td>\n",
       "      <td>0.958226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.703144</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>0.664858</td>\n",
       "      <td>0.955867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9.733331</td>\n",
       "      <td>0.101031</td>\n",
       "      <td>0.619632</td>\n",
       "      <td>0.957399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.779461</td>\n",
       "      <td>0.087963</td>\n",
       "      <td>0.726593</td>\n",
       "      <td>0.956218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv  fit_time  score_time  test_score  train_score\n",
       "0   0  9.789462    0.122772    0.567467     0.958550\n",
       "1   1  9.783456    0.097236    0.618854     0.958226\n",
       "2   2  9.703144    0.096081    0.664858     0.955867\n",
       "3   3  9.733331    0.101031    0.619632     0.957399\n",
       "4   4  9.779461    0.087963    0.726593     0.956218"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate to obtain test and train scores as well as fit and score time\n",
    "scores = cross_validate(best_regressor_rf, X, y, return_train_score=True, cv=10)\n",
    "scores_df = pd.DataFrame(scores).reset_index().rename(columns={'index':'cv'})\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for linear regressor with Random Forest Regressor:\n",
      "0.69 mean accuracy with a mean standard deviation of 0.08\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation results for linear regressor with Random Forest Regressor:')\n",
    "print(\"%0.2f mean accuracy with a mean standard deviation of %0.2f\" % (scores_df.test_score.mean(), scores_df.test_score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to cross validation of Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Ridge regressor:  {'alpha': 1.5, 'tol': 1e-05}\n",
      "Best R2 score :  0.7062874256314109\n"
     ]
    }
   ],
   "source": [
    "# Confirm best hyperparameters of Ridge through GridSearch\n",
    "regressor_ridge = Ridge()\n",
    "\n",
    "# Grid of values to be tested: (alpha ==0 is equivalent to ordinary least squares solved by a linear regressor; tol = precision of the solution - default 1e-03)\n",
    "params = {\n",
    "    'alpha': [0.0, 0.1, 0.5, 1.0, 1.5],\n",
    "    'tol': [1e-05, 1e-04, 1e-03]\n",
    "}\n",
    "gridsearch = GridSearchCV(regressor_ridge, param_grid = params, cv = 10)\n",
    "gridsearch.fit(X_train_t, y_train)\n",
    "\n",
    "print(\"Best hyperparameters for Ridge regressor: \", gridsearch.best_params_)\n",
    "print(\"Best R2 score : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/aura.moreno/Documents/Jedha/fullstack_datascience/05-Getaround_app_deployment/api_endpoint/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.623242</td>\n",
       "      <td>0.715776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.599449</td>\n",
       "      <td>0.716558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.627115</td>\n",
       "      <td>0.713049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.616235</td>\n",
       "      <td>0.709882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.730865</td>\n",
       "      <td>0.706684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv  fit_time  score_time  test_score  train_score\n",
       "0   0  0.018976    0.003355    0.623242     0.715776\n",
       "1   1  0.016574    0.003057    0.599449     0.716558\n",
       "2   2  0.017900    0.002736    0.627115     0.713049\n",
       "3   3  0.015859    0.002559    0.616235     0.709882\n",
       "4   4  0.015953    0.002752    0.730865     0.706684"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate to obtain test and train scores as well as fit and score time\n",
    "best_regressor_ridge = Pipeline([\n",
    "        ('preprocessing', featureencoder),\n",
    "        ('lin_reg', Ridge(alpha=1.5, tol=1e-05))\n",
    "    ])\n",
    "\n",
    "\n",
    "scores = cross_validate(best_regressor_ridge, X, y, return_train_score=True, cv=10)\n",
    "scores_df = pd.DataFrame(scores).reset_index().rename(columns={'index':'cv'})\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for linear regressor with Ridge Regressor:\n",
      "0.65 mean accuracy with a mean standard deviation of 0.07\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation results for linear regressor with Ridge Regressor:')\n",
    "print(\"%0.2f mean accuracy with a mean standard deviation of %0.2f\" % (scores_df.test_score.mean(), scores_df.test_score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export of best model  \n",
    "\n",
    "Whilst at first the Random Forest Regressor appeared to perform better, following cross validation I preferred to choose the Rige model which has similar stability (lower mean sd)as we can better interpret it regarding feature contribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/reg_model.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor_ridge.fit(X_train, y_train)\n",
    "joblib.dump(best_regressor_ridge, \"../models/reg_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary  \n",
    "The best model identified was the Ridge regressor with a mean accuracy score of 0.65 and a mean standard deviation of 0.07 across a 10-fold crossvalidation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  [0, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                   11, 12]),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  [1, 2])])),\n",
       "                ('lin_reg', Ridge(alpha=1.5, tol=1e-05))])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor_ridge.get_params\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd44dc819572b2b78bf39e6901e46fbecc7b90b284cd3dd297da5170fea9a38b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
